import 'dart:convert';
import 'dart:io';
import 'dart:isolate';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:voicevox_flutter/voicevox_flutter.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as p;

// ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ https://github.com/char5742/voicevox_flutter/blob/dependency-voicevox_core-v0.15.0-preview.13/example/lib/service.dart (271c918) ã‚’æ”¹å¤‰ã—ãŸã‚‚ã®ã§ã™ã€‚
// ãƒ©ã‚¤ã‚»ãƒ³ã‚¹:  https://github.com/char5742/voicevox_flutter/blob/dependency-voicevox_core-v0.15.0-preview.13/LICENSE
// è¬è¾ã¨è¬ç½ª: char5742ã•ã‚“ã€ç´ æ™´ã‚‰ã—ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ãã—ã¦åˆå¿ƒè€…æ„Ÿä¸¸å‡ºã—ãªæ”¹é€ ã‚’ãŠè©«ã³ã—ã¾ã™â€¦ï¼

class NativeVoiceService {
  late final Isolate isolate;
  late final SendPort sendPort;

  // æ—©é€Ÿã‚ªãƒªãƒãƒ£ãƒ¼ç™ºå‹•ï¼å¿…è¦ã«ãªã£ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã‚³ã‚¢ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¾ã›ã‚‹ã‚ˆã†ã«ã—ãŸ
  final List<String> _loadedModelNames = []; // èª­ã¿è¾¼ã¿æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«å.vvmã‚’æ ¼ç´ã™ã‚‹
  late final Map<String, dynamic> _modelNameMapCache; // {"styleId": "modelName.vvm"}å½¢å¼ã®ãƒãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã€‚lateã®ä½¿ã„æ–¹ã‚ã‹ã‚‰ã‚“ğŸ™ƒ

  Future<void> initialize() async {
    final modelNameMapAsText = await rootBundle.loadString('assets/styleIdToModelName.json');
    _modelNameMapCache = json.decode(modelNameMapAsText);

    final receivePort = ReceivePort();
    final rootToken = RootIsolateToken.instance!;
    isolate = await Isolate.spawn<(SendPort, RootIsolateToken)>((message) async {
      BackgroundIsolateBinaryMessenger.ensureInitialized(message.$2);

      final receivePort = ReceivePort();
      message.$1.send(receivePort.sendPort);

      receivePort.listen((message) async {
        message = message as Map<String, dynamic>;

        switch (message['method']) {
          case 'initialize':
            await _initialize(
              message['openJdkDictPath'] as String,
            );
            (message['sendPort'] as SendPort).send(null);
          case 'audioQuery':
            (message['sendPort'] as SendPort).send(
              _audioQuery(message['text'] as String, message['styleId'] as int),
            );
          case 'synthesis':
            (message['sendPort'] as SendPort).send(
              await _synthesis(message['query'] as String, message['styleId'] as int),
            );
          case 'tts':
            (message['sendPort'] as SendPort).send(
              await _tts(message['query'] as String, message['styleId'] as int),
            );
          case 'loadVoiceModel':
            await _loadVoiceModel(
              message['modelPath'] as String,
            );
            (message['sendPort'] as SendPort).send(null);
        }
      });
    }, (receivePort.sendPort, rootToken));
    sendPort = await receivePort.first as SendPort;

    final r = ReceivePort();
    sendPort.send({
      'method': 'initialize', // ã“ã‚Œã«ã‚ˆã£ã¦å‹•ãã®ã¯_initialize
      'openJdkDictPath': await _setOpenJdkDict(),
      'sendPort': r.sendPort,
    });
    await r.first;
  }

  /// ã‚ªãƒªãƒãƒ£ãƒ¼ã®æ ¹å¹¹éƒ¨åˆ†ã€‚ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ãªå‡¦ç†ã®å‰ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã€‚ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã«ã™ã‚‹ã¨è‹¥å¹²é«˜é€ŸåŒ–ã®é“ãŒé–‹ã‘ã‚‹ã‹ã‚‚ï¼Ÿ
  Future<void> _prepairModel(int styleId) async {
    final requiredModelName = _modelNameMapCache[styleId.toString()];

    if (requiredModelName == null) {
      Exception('ã“ã®styleId: $styleIdã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«.vvmãŒã©ã‚Œãªã®ã‹ã‚ã‹ã‚Šã¾ã›ã‚“ğŸ˜« assetsã®styleIdToModelName.jsonã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚');
    }

    if (_loadedModelNames.contains(requiredModelName)) {
      return;
    }

    print('${DateTime.now()}ğŸ˜¸VVMãƒ¢ãƒ‡ãƒ«$requiredModelNameãŒå¿…è¦ã«ãªã£ãŸã®ã§ã‚³ã‚¢ã«èª­ã¿è¾¼ã¾ã›ã¾ã™');

    /// ã‚¢ã‚»ãƒƒãƒˆã‹ã‚‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`model`ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
    const modelAssetDir = 'assets/model';
    final modelDir = Directory('${(await getApplicationSupportDirectory()).path}/model');
    modelDir.createSync();
    await _copyFile(requiredModelName, modelAssetDir, modelDir.path);

    // ã‚³ã‚¢ã«èª­ã¿è¾¼ã¾ã›ã‚‹ï¼ˆRAMã«å±•é–‹ã™ã‚‹ï¼Ÿï¼‰
    final receivePort = ReceivePort();
    sendPort.send({
      'method': 'loadVoiceModel',
      'modelPath': '${modelDir.path}/$requiredModelName',
      'sendPort': receivePort.sendPort,
    });
    await receivePort.first;

    print('${DateTime.now()}ğŸ˜¹ã‚³ã‚¢ã«VVMãƒ¢ãƒ‡ãƒ«${modelDir.path}/$requiredModelNameã‚’èª­ã¿è¾¼ã¾ã›ã¾ã—ãŸ');
    _loadedModelNames.add(requiredModelName);
  }

  /// AudioQuery ã‚’ç”Ÿæˆã™ã‚‹
  Future<String> audioQuery(String text, int styleId) async {
    await _prepairModel(styleId); // ã‚ªãƒªãƒãƒ£ãƒ¼

    final receivePort = ReceivePort();
    sendPort.send({
      'method': 'audioQuery',
      'text': text,
      'styleId': styleId,
      'sendPort': receivePort.sendPort,
    });
    return (await receivePort.first) as String;
  }

  /// AudioQueryã‹ã‚‰åˆæˆã‚’å®Ÿè¡Œã™ã‚‹
  Future<String> synthesis(String query, int styleId) async {
    await _prepairModel(styleId); // ã‚ªãƒªãƒãƒ£ãƒ¼

    final receivePort = ReceivePort();
    sendPort.send({
      'method': 'synthesis',
      'query': query,
      'styleId': styleId,
      'sendPort': receivePort.sendPort,
    });
    return (await receivePort.first) as String;
  }

  /// ãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°åˆæˆã‚’å®Ÿè¡Œã™ã‚‹
  Future<String> tts(String query, int styleId) {
    // await prepairModel(styleId); // ã‚ªãƒªãƒãƒ£ãƒ¼â€¦ã¨æ€ã£ãŸã‚‰ã“ã‚Œã ã‘asyncã˜ã‚ƒãªã„ã€‚ä½¿ã£ã¦ãªã„ã®ã§ãã®ã¾ã¾ã«ã—ãŸ

    final receivePort = ReceivePort();
    sendPort.send({
      'method': 'tts',
      'query': query,
      'styleId': styleId,
      'sendPort': receivePort.sendPort,
    });
    return receivePort.first as Future<String>;
  }

  void dispose() {
    isolate.kill();
  }
} // isolateã€å®Œå…¨ã«ç†è§£ã—ãŸã€‚ã‚‚ã¯ã‚„ã¡ã‚ƒã‚“ã¨ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§å‹•ãã‹ãªã‚“ã¦ã©ã†ã§ã‚‚ã„ã„ï¼

Future<void> _initialize(String openJdkDictPath) async {
  await VoicevoxFlutter.instance.initialize(
    openJdkDictPath: openJdkDictPath,
    cpuNumThreads: 4,
  );
}

Future<void> _loadVoiceModel(String modelPath) async {
  VoicevoxFlutter.instance.loadVoiceModel(modelPath);
}

String _audioQuery(String text, int styleId) {
  return VoicevoxFlutter.instance.audioQuery(text, styleId: styleId);
}

Future<String> _synthesis(String query, int styleId) async {
  final wavFile = File('${(await getApplicationDocumentsDirectory()).path}/${query.hashCode}.wav');
  final watch = Stopwatch()..start();
  VoicevoxFlutter.instance.synthesis(
    query,
    styleId: styleId,
    outputPath: wavFile.path,
  );
  watch.stop();
  // åˆæˆã«ã‹ã‹ã£ãŸæ™‚é–“ã‚’è¡¨ç¤ºã™ã‚‹
  debugPrint('â­ï¸${watch.elapsedMilliseconds}msã§åˆæˆã—ã¦${wavFile.path}ã«ä¿å­˜ã—ã¾ã—ãŸ');
  return wavFile.path;
}

/// ãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°åˆæˆã‚’å®Ÿè¡Œã™ã‚‹
Future<String> _tts(String query, int styleId) async {
  final wavFile = File('${(await getApplicationDocumentsDirectory()).path}/voice.wav');
  final watch = Stopwatch()..start();
  VoicevoxFlutter.instance.tts(
    query,
    styleId: styleId,
    outputPath: wavFile.path,
  );
  watch.stop();
  // åˆæˆã«ã‹ã‹ã£ãŸæ™‚é–“ã‚’è¡¨ç¤ºã™ã‚‹
  debugPrint('â­ï¸${watch.elapsedMilliseconds}msã§åˆæˆã—ã¦${wavFile.path}ã«ä¿å­˜ã—ã¾ã—ãŸ');
  return wavFile.path;
}

//

/// ã‚¢ã‚»ãƒƒãƒˆã‹ã‚‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
Future<void> _copyFile(String filename, String assetsDir, String targetDirPath) async {
  final data = await rootBundle.load('$assetsDir/$filename');
  final bytes = data.buffer.asUint8List(data.offsetInBytes, data.lengthInBytes);
  File('$targetDirPath/$filename').writeAsBytesSync(bytes);
}

/// ã‚¢ã‚»ãƒƒãƒˆã‹ã‚‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`open_jtalk_dict`ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
Future<String> _setOpenJdkDict() async {
  final openJdkDictDir = Directory('${(await getApplicationSupportDirectory()).path}/open_jtalk_dic_utf_8-1.11');

  if (!openJdkDictDir.existsSync()) {
    openJdkDictDir.createSync();
    const openJdkDicAssetDir = 'assets/open_jtalk_dic_utf_8-1.11';

    final manifestContent = await rootBundle.loadString('AssetManifest.json');
    final manifestMap = json.decode(manifestContent) as Map<String, dynamic>;
    // open_jtalk_dic_utf_8-1.11ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
    manifestMap.keys.where((e) => e.contains(openJdkDicAssetDir)).map(p.basename).forEach((name) async {
      await _copyFile(name, openJdkDicAssetDir, openJdkDictDir.path);
    });
    await Future.delayed(const Duration(seconds: 1)); // åˆå›èµ·å‹•æ™‚ã«ä¾‹å¤–ãŒå‡ºã‚‹ãŸã‚ã€‚é«˜é€ŸåŒ–ã®è³œç‰©ï¼ŸğŸ˜Œ
  }
  return openJdkDictDir.path;
}
